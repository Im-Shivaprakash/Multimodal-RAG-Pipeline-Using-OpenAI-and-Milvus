{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser, Document\n",
    "from langchain_milvus import Milvus\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_content(file_path):\n",
    "    chunks = partition_pdf(\n",
    "        filename=file_path,\n",
    "        infer_table_structure=True,\n",
    "        strategy=\"hi_res\",\n",
    "        extract_image_block_types=[\"Image\", \"Table\"],\n",
    "        extract_image_block_to_payload=True,\n",
    "        chunking_strategy=\"by_title\",\n",
    "        max_characters=10000,\n",
    "        combine_text_under_n_chars=2000,\n",
    "        new_after_n_chars=6000,\n",
    "    )\n",
    "    texts, tables, images = [], [], []\n",
    "    for chunk in chunks:\n",
    "        if \"CompositeElement\" in str(type(chunk)):\n",
    "            texts.append(chunk.text)\n",
    "            for el in chunk.metadata.orig_elements:\n",
    "                if \"Table\" in str(type(el)):\n",
    "                    tables.append(el.metadata.text_as_html)\n",
    "                elif \"Image\" in str(type(el)):\n",
    "                    images.append(el.metadata.image_base64)\n",
    "    return texts, tables, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_content(texts, tables, images):\n",
    "    model = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.5)\n",
    "    \n",
    "    prompt_text = \"\"\"You are an assistant summarizing text and tables. Provide a concise summary of the given content:\n",
    "    {element}\"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "    summarize_chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 3})\n",
    "    table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 3})\n",
    "    \n",
    "    image_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"user\", [\n",
    "            {\"type\": \"text\", \"text\": \"Describe the image in detail.\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/jpeg;base64,{image}\"}},\n",
    "        ])\n",
    "    ])\n",
    "    chain = image_prompt | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser()\n",
    "    image_summaries = chain.batch(images)\n",
    "    \n",
    "    return text_summaries, table_summaries, image_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_vectors(texts, text_summaries, tables, table_summaries, images, image_summaries):\n",
    "    # Initialize Milvus and InMemoryStore\n",
    "    vectorstore = Milvus(\n",
    "        collection_name=\"multi_modal_rag\",\n",
    "        embedding_function=OpenAIEmbeddings(),\n",
    "        connection_args={\"uri\": \"http://localhost:19530\"},\n",
    "    )\n",
    "    store = InMemoryStore()\n",
    "    retriever = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "\n",
    "    # Helper function to add data to the store\n",
    "    def add_to_store(data, summaries):\n",
    "        ids = [str(uuid.uuid4()) for _ in data]\n",
    "        documents = [Document(page_content=summaries[i], metadata={\"doc_id\": ids[i], \"id\": ids[i]}) for i in range(len(data))]\n",
    "        retriever.vectorstore.add_documents(documents, ids=ids)\n",
    "        retriever.docstore.mset(list(zip(ids, data)))\n",
    "\n",
    "    # Store text, tables, and images\n",
    "    add_to_store(texts, text_summaries)\n",
    "    add_to_store(tables, table_summaries)\n",
    "    add_to_store(images, image_summaries)\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs(docs):\n",
    "    b64, text = [], []\n",
    "    for doc in docs:\n",
    "        if isinstance(doc, Document):\n",
    "            if \"image_base64\" in doc.metadata:  # Check if it's an image\n",
    "                b64.append(doc.metadata[\"image_base64\"])\n",
    "            else:\n",
    "                text.append(doc)\n",
    "    return {\"images\": b64, \"texts\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_base64_image(base64_code):\n",
    "    if base64_code:\n",
    "        image_data = base64.b64decode(base64_code)\n",
    "        display(Image(data=image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(kwargs):\n",
    "    docs_by_type = kwargs[\"context\"]\n",
    "    user_question = kwargs[\"question\"]\n",
    "    context_text = \"\".join([text_element.page_content for text_element in docs_by_type[\"texts\"]])\n",
    "\n",
    "    prompt_content = [{\"type\": \"text\", \"text\": f\"\"\"\n",
    "        Answer the question based only on the following context:\n",
    "        Context: {context_text}\n",
    "        Question: {user_question}\n",
    "    \"\"\"}]\n",
    "\n",
    "    # Add images to the prompt\n",
    "    if docs_by_type[\"images\"]:\n",
    "        for image in docs_by_type[\"images\"]:\n",
    "            prompt_content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"}})\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([HumanMessage(content=prompt_content)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotState:\n",
    "    def __init__(self, context=None, question=None, response=None, generated_prompt=None):\n",
    "        self.context = context\n",
    "        self.question = question\n",
    "        self.response = response\n",
    "        self.generated_prompt = generated_prompt\n",
    "\n",
    "\n",
    "graph = StateGraph(ChatbotState)\n",
    "\n",
    "# Node 1: Retrieve context from retriever\n",
    "graph.add_node(\"retrieve\", lambda state: ChatbotState(\n",
    "    context={\"docs\": retriever.invoke(state.question)}, \n",
    "    question=state.question\n",
    "))\n",
    "\n",
    "# Node 2: Parse retrieved documents\n",
    "graph.add_node(\"parse\", lambda state: ChatbotState(\n",
    "    context=state.context, \n",
    "    question=state.question,\n",
    "    response=state.response,\n",
    "    generated_prompt=parse_docs(state.context[\"docs\"])[\"parsed_context\"]\n",
    "))\n",
    "\n",
    "# Node 3: Build the prompt for LLM\n",
    "graph.add_node(\"prompt\", lambda state: ChatbotState(\n",
    "    context=state.context, \n",
    "    question=state.question,\n",
    "    response=state.response,\n",
    "    generated_prompt=build_prompt({\"context\": state.prompt, \"question\": state.question})\n",
    "))\n",
    "\n",
    "# Node 4: Generate response using GPT-4o-mini\n",
    "graph.add_node(\"generate\", lambda state: ChatbotState(\n",
    "    context=state.context, \n",
    "    question=state.question, \n",
    "    response=ChatOpenAI(model=\"gpt-4o-mini\").invoke(state.prompt).text  # Fixed to use 'state.prompt'\n",
    "))\n",
    "\n",
    "# Define graph flow\n",
    "graph.add_edge(\"retrieve\", \"parse\")\n",
    "graph.add_edge(\"parse\", \"prompt\")\n",
    "graph.add_edge(\"prompt\", \"generate\")\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "\n",
    "# Compile chatbot\n",
    "chatbot = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Attention-is-all-you-need.pdf\"\n",
    "texts, tables, images = extract_pdf_content(file_path)\n",
    "text_summaries, table_summaries, image_summaries = summarize_content(texts, tables, images)\n",
    "retriever = store_vectors(texts, text_summaries, tables, table_summaries, images, image_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Must write to at least one of []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mChatbotState\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExplain the multihead attention?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Print text response\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1929\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1928\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1929\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1933\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1939\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1649\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1649\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1656\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:105\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    103\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:44\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, writer)\u001b[0m\n\u001b[0;32m     42\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:176\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m    175\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m--> 176\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    178\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\write.py:85\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     80\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m write\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[0;32m     84\u001b[0m     ]\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_at_least_one_of\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\TESS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langgraph\\pregel\\write.py:142\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[1;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m require_at_least_one_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m {chan \u001b[38;5;28;01mfor\u001b[39;00m chan, _ \u001b[38;5;129;01min\u001b[39;00m filtered} \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(require_at_least_one_of):\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust write to at least one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequire_at_least_one_of\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m         )\n\u001b[0;32m    145\u001b[0m write: TYPE_SEND \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_SEND]\n\u001b[0;32m    146\u001b[0m write(sends \u001b[38;5;241m+\u001b[39m filtered)\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m: Must write to at least one of []",
      "\u001b[0mDuring task with name '__start__' and id 'ab0a4667-54e4-1414-4316-38225127846d'"
     ]
    }
   ],
   "source": [
    "response = chatbot.invoke(ChatbotState(question=\"Explain the multihead attention?\"))\n",
    "\n",
    "# Print text response\n",
    "print(\"Response:\", response.response)\n",
    "\n",
    "# Display images if available\n",
    "if response.context.get(\"images\"):\n",
    "    for image in response.context[\"images\"]:\n",
    "        display_base64_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
